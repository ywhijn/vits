import argparse, csv, os
from datetime import datetime

def get_parser():
    parser = argparse.ArgumentParser(
        formatter_class=argparse.ArgumentDefaultsHelpFormatter
    )
    parser.add_argument(
        "--extra_data",
        type=str,
        default=None,
        help="ertra data name"
    )
    parser.add_argument(
        "--cuda_device",
        type=str,
        default="0,1,2,3,4,5,6,7",
        help="Master port to use for DDP training.",
    )
    parser.add_argument(
        "--epoch",
        type=int,
        default=30,
        help="""It specifies the checkpoint to use for decoding.
        Note: Epoch counts from 1.
        You can specify --avg to use more checkpoints for model averaging.""",
    )

    parser.add_argument(
        "--batch_size",
        type=int,
        default=64,
    )

    parser.add_argument(
        "--unit_num",
        type=int,
        default=1000,
    )
    parser.add_argument(
        "--cuts_path",
        type=str,
        default="/home/ma-user/work/yangwenhan/zipformer/data/ctc_units",
        help="The cuts dir generated by icefall, determine the exper name",
    )

    parser.add_argument(
        "--config_dir",
        type=str,
        default="/home/ma-user/work/yangwenhan/u2s/person/config"
    )

    parser.add_argument(
        "--output_model_path",
        type=str,
        default="/home/ma-user/work/yangwenhan/u2s/model/",
        help="common synthesis audio path, followed by expr name",
    )
    parser.add_argument(
        "--checkpoint_dir",
        type=str,
        default=None,
        help="if None, load beat G in the exp",
    )
    parser.add_argument(
        "--model_id",
        type=str,
        default="/home/ma-user/work/daxintan/llama_omni_model/whisper-large-v3_hf/",
        help="whisper",
    )
    parser.add_argument(
        "--audio_output_dir",
        type=str,
        default="/home/ma-user/work/yangwenhan/data/speech_reconstruction/",
        help = "common synthesis audio path, followed by expr name",
    )

    parser.add_argument(
        "--input_path",
        type=str,
        default="/home/ma-user/work/yangwenhan/u2s/data/",
        help = "common units input path, followed by expr name",
    )
    parser.add_argument(
        "--expr_name",
        type=str,
        default="960LS_100hFTbpeUnit",
        help="The experiment res dir, trained model saved",
    )

    parser.add_argument(
        "--train",
        type=str2bool,
        default=0,
    )
    parser.add_argument(
        "--synthesis",
        type=str2bool,
        default=1,
    )
    parser.add_argument(
        "--num_gpu",
        type=int,
        default=8,
    )

    parser.add_argument(
        "--res_dir",
        type=str,
        default="/home/ma-user/work/yangwenhan/trainlog/u2s_res.csv",
        help="csv res",
    )
    return parser
def merge_consecutive(lst):
    if not lst:
        return []
    result = [lst[0]]
    for num in lst[1:]:
        if num != result[-1]:
            result.append(num)
    return result
def pre_process_units(units_list):
    int_list = merge_consecutive([str(int(num)) for num in units_list])
    return int_list
def str2bool(v):
    """Used in argparse.ArgumentParser.add_argument to indicate
    that a type is a bool type and user can enter

        - yes, true, t, y, 1, to represent True
        - no, false, f, n, 0, to represent False
    See https://stackoverflow.com/questions/15008758/parsing-boolean-values-with-argparse  # noqa
    """
    if isinstance(v, bool):
        return v
    if v.lower() in ("yes", "true", "t", "y", "1"):
        return True
    elif v.lower() in ("no", "false", "f", "n", "0"):
        return False
    else:
        raise argparse.ArgumentTypeError("Boolean value expected.")


# class ExperimentLogger:
#     def __init__(self, file_path):
#         self.file_path = file_path
#         self.columns = ['exp_name', 'src_model', 'dev-clean', 'dev-other', 'test-clean', 'test-other', 'average_wer',
#                         'time']

#         if not os.path.exists(self.file_path):
#             with open(self.file_path, 'w', newline='') as f:
#                 writer = csv.DictWriter(f, fieldnames=self.columns)
#                 writer.writeheader()

#     def add_record(self, expr_name, results):
#         record = {
#             'exp_name': expr_name,
#             'src_model': results['src_model'],
#             'dev-clean': results['dev-clean'],
#             'dev-other': results['dev-other'],
#             'test-clean': results['test-clean'],
#             'test-other': results['test-other'],
#             'average_wer': results['average_wer'],
#             'time': datetime.now().strftime("%m-%d %H:%M")
#         }

#         with open(self.file_path, 'a', newline='') as f:
#             writer = csv.DictWriter(f, fieldnames=self.columns)
#             writer.writerow(record)

#     def display(self):
#         with open(self.file_path, 'r') as f:
#             reader = csv.DictReader(f)
#             for row in reader:
#                 print(row)
import re
def find_latest_checkpoint_num(path):
    files = [f for f in os.listdir(path) ]
    pths = [f for f in files if ( f.startswith('G_') and f.endswith(".pth") ) ]
    if not pths:
        return None
    max_number = max(int(re.search(r'\d+', f).group()) for f in pths)
    
    return max_number
class ErtraExperimentLogger:
    def __init__(self, file_path):
        prefix="extra_"
        directory, filename = os.path.split(file_path)
        new_filename = prefix + filename 
        self.file_path = os.path.join(directory, new_filename)
        self.columns = ['exp_name', 'model_id', 'chime3-enh', 'time', 'total_time']

        if not os.path.exists(self.file_path):
            with open(self.file_path, 'w', newline='') as f:
                writer = csv.DictWriter(f, fieldnames=self.columns)
                writer.writeheader()

    def add_record(self, results):
        record = {
            'exp_name': results['exp_name'],
            'model_id': results['model_id'],
            'chime3-enh': results['chime3-enh'],
            'time': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            'total_time': results['total_time']
        }

        with open(self.file_path, 'a', newline='') as f:
            writer = csv.DictWriter(f, fieldnames=self.columns)
            writer.writerow(record)

    def display(self):
        with open(self.file_path, 'r') as f:
            reader = csv.DictReader(f)
            for row in reader:
                print(row)
class AllExperimentLogger:
    def __init__(self, file_path):
        prefix="all_"
        directory, filename = os.path.split(file_path)
        new_filename = prefix + filename
        self.file_path = os.path.join(directory, new_filename)
        self.columns = ['exp_name', 'model_id',  'chime3-enh','dev-clean', 'dev-other', 'test-clean', 'test-other', 'average_wer',
                        'time', 'total_time']

        if not os.path.exists(self.file_path):
            with open(self.file_path, 'w', newline='') as f:
                writer = csv.DictWriter(f, fieldnames=self.columns)
                writer.writeheader()

    def add_record(self, results):
        record = {
            'exp_name': results['exp_name'],
            'model_id': results['model_id'],
            'chime3-enh': results['chime3-enh'],
            'dev-clean': results['dev-clean'],
            'dev-other': results['dev-other'],
            'test-clean': results['test-clean'],
            'test-other': results['test-other'],
            'average_wer': results['average_wer'],
            'time': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            'total_time': results['total_time']
        }

        with open(self.file_path, 'a', newline='') as f:
            writer = csv.DictWriter(f, fieldnames=self.columns)
            writer.writerow(record)

    def display(self):
        with open(self.file_path, 'r') as f:
            reader = csv.DictReader(f)
            for row in reader:
                print(row)
class ExperimentLogger:
    def __init__(self, file_path):
        self.file_path = file_path
        self.columns = ['exp_name', 'model_id', 'dev-clean', 'dev-other', 'test-clean', 'test-other', 'average_wer',
                        'time', 'total_time']

        if not os.path.exists(self.file_path):
            with open(self.file_path, 'w', newline='') as f:
                writer = csv.DictWriter(f, fieldnames=self.columns)
                writer.writeheader()

    def add_record(self, results):
        record = {
            'exp_name': results['exp_name'],
            'model_id': results['model_id'],
            'dev-clean': results['dev-clean'],
            'dev-other': results['dev-other'],
            'test-clean': results['test-clean'],
            'test-other': results['test-other'],
            'average_wer': results['average_wer'],
            'time': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            'total_time': results['total_time']
        }

        with open(self.file_path, 'a', newline='') as f:
            writer = csv.DictWriter(f, fieldnames=self.columns)
            writer.writerow(record)

    def display(self):
        with open(self.file_path, 'r') as f:
            reader = csv.DictReader(f)
            for row in reader:
                print(row)
import json
from typing import Dict, Any

class ConfigManager:
    def __init__(self, config_path: str):
        self.config_path = config_path
        self.config = self.load_config()

    def load_config(self) -> Dict[str, Any]:
        with open(self.config_path, 'r') as file:
            return json.load(file)

    def save_config(self, output_path: str = None):
        if output_path is None:
            output_path = self.config_path
        with open(output_path, 'w') as file:
            json.dump(self.config, file, indent=2)

    def update_field(self, section: str, field: str, value: Any):
        print(field,value )
        if section not in self.config:
            raise ValueError(f"Section '{section}' not found in config")
        if field not in self.config[section]:
            raise ValueError(f"Field '{field}' not found in section '{section}'")
        self.config[section][field] = value

    def get_field(self, section: str, field: str) -> Any:
        if section not in self.config:
            raise ValueError(f"Section '{section}' not found in config")
        if field not in self.config[section]:
            raise ValueError(f"Field '{field}' not found in section '{section}'")
        return self.config[section][field]

# 使用示例
if __name__ == "__main__":
    # 初始化配置管理器
    config_manager = ConfigManager("config.json")

    # 修改字段
    config_manager.update_field("train", "learning_rate", 1e-4)
    config_manager.update_field("data", "sampling_rate", 44100)
    config_manager.update_field("model", "hidden_channels", 256)

    # 获取字段值
    lr = config_manager.get_field("train", "learning_rate")
    print(f"Updated learning rate: {lr}")
    config_manager.save_config("updated_config.json")
    print("Configuration updated and saved.")
